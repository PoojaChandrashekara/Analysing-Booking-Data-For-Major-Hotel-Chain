{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_X' from 'imblearn.utils._validation' (c:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "File \u001b[1;32mc:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32mc:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[1;32mc:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE, BorderlineSMOTE\n",
      "File \u001b[1;32mc:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _n_jobs_docstring, _random_state_docstring\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HasMethods, Interval, StrOptions\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_X\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, _mode\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_check_X' from 'imblearn.utils._validation' (c:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py)"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset into a pandas dataframe\n",
    "file_path = os.path.join('data', 'Booking_Data_Cleaned.csv')\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Booking Date</th>\n",
       "      <th>Arrival Date</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Guests</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Deposit Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Stay Duration Category</th>\n",
       "      <th>Revenue Category</th>\n",
       "      <th>Revenue Loss Category</th>\n",
       "      <th>ADR Category</th>\n",
       "      <th>Booking Month</th>\n",
       "      <th>Booking Day</th>\n",
       "      <th>Arrival Month</th>\n",
       "      <th>Arrival Day</th>\n",
       "      <th>Booking Year</th>\n",
       "      <th>Arrival Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort</td>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Transient</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>...</td>\n",
       "      <td>short</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>July</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Transient</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>...</td>\n",
       "      <td>short</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>June</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Transient</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>...</td>\n",
       "      <td>short</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>June</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Online Travel Agent</td>\n",
       "      <td>Transient</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>...</td>\n",
       "      <td>short</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>June</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Online Travel Agent</td>\n",
       "      <td>Transient</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>...</td>\n",
       "      <td>short</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>June</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hotel Booking Date Arrival Date  Lead Time  Nights  Guests  \\\n",
       "0  Resort   2014-07-24   2015-07-01        342       0       2   \n",
       "1  Resort   2015-06-24   2015-07-01          7       1       1   \n",
       "2  Resort   2015-06-18   2015-07-01         13       1       1   \n",
       "3  Resort   2015-06-17   2015-07-01         14       2       2   \n",
       "4  Resort   2015-06-17   2015-07-01         14       2       2   \n",
       "\n",
       "  Distribution Channel Customer Type         Country Deposit Type  ...  \\\n",
       "0               Direct     Transient        Portugal   No Deposit  ...   \n",
       "1               Direct     Transient  United Kingdom   No Deposit  ...   \n",
       "2            Corporate     Transient  United Kingdom   No Deposit  ...   \n",
       "3  Online Travel Agent     Transient  United Kingdom   No Deposit  ...   \n",
       "4  Online Travel Agent     Transient  United Kingdom   No Deposit  ...   \n",
       "\n",
       "   Stay Duration Category Revenue Category Revenue Loss Category  \\\n",
       "0                   short              low                   low   \n",
       "1                   short              low                   low   \n",
       "2                   short              low                   low   \n",
       "3                   short           medium                   low   \n",
       "4                   short           medium                   low   \n",
       "\n",
       "   ADR Category  Booking Month  Booking Day Arrival Month Arrival Day  \\\n",
       "0           low           July     Thursday          July   Wednesday   \n",
       "1           low           June    Wednesday          July   Wednesday   \n",
       "2           low           June     Thursday          July   Wednesday   \n",
       "3           low           June    Wednesday          July   Wednesday   \n",
       "4           low           June    Wednesday          July   Wednesday   \n",
       "\n",
       "  Booking Year Arrival Year  \n",
       "0         2014         2015  \n",
       "1         2015         2015  \n",
       "2         2015         2015  \n",
       "3         2015         2015  \n",
       "4         2015         2015  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the dataset very imabalanced from univariate analysis of Cancelled column. Lets balance the dataset using SMOTE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_features = X_train.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Create a column transformer with appropriate transformers for categorical and numerical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor and transform the training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Fit SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# Checking the balance after SMOTE\n",
    "print(f\"Before SMOTE, counts of label '1': {sum(y_train == 1)}\")\n",
    "print(f\"Before SMOTE, counts of label '0': {sum(y_train == 0)}\\n\")\n",
    "print(f\"After SMOTE, counts of label '1': {sum(y_train_smote == 1)}\")\n",
    "print(f\"After SMOTE, counts of label '0': {sum(y_train_smote == 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1ga17\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.00\n",
      "Logistic Regression Precision: 1.00\n",
      "Logistic Regression Recall: 1.00\n",
      "Logistic Regression F1-Score: 1.00\n",
      "Logistic Regression ROC-AUC: 1.00\n",
      "\n",
      "Random Forest Accuracy: 1.00\n",
      "Random Forest Precision: 1.00\n",
      "Random Forest Recall: 1.00\n",
      "Random Forest F1-Score: 1.00\n",
      "Random Forest ROC-AUC: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separating features and target variable\n",
    "X = df.drop(['Cancelled (0/1)'], axis=1)\n",
    "y = df['Cancelled (0/1)']\n",
    "\n",
    "# Identifying categorical columns for one-hot encoding\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Creating a preprocessing pipeline for automatic one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Passthrough numerical columns as they are\n",
    ")\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Logistic Regression Model\n",
    "lr_pipeline = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_pipeline = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100))\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "for model, name in zip([lr_pipeline, rf_pipeline], ['Logistic Regression', 'Random Forest']):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"{name} Precision: {precision_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"{name} Recall: {recall_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"{name} F1-Score: {f1_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"{name} ROC-AUC: {roc_auc_score(y_test, y_pred):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
